# longtext20260110
长文本处理小程序，自带图形处理界面，使用简单，可适配本地大模型和网络大模型，字数无上限，采用拆分——批处理——合并的三个模块处理，仿酒馆设计，允许加载提示词、预设以及正则（懂的都懂），使用本程序需自备大模型的API。

## 模块1：文本分块工具使用说明
功能简介
本工具提供两种文本分块模式，适用于大语言模型（LLM）输入预处理等场景：
模式 A（Token 精细分块）：按指定 Token 数量切分文本，自动保留句子/段落边界，并支持重叠以避免语义割裂。
模式 B（章节分块）：基于章节标题智能识别，将完整章节组合成块，确保内容逻辑完整性。
使用方法
运行程序
双击运行脚本，将弹出图形界面（GUI）。
首次使用请确保已安装依赖：pip install tiktoken
选择文件
点击“选择文件”按钮，选取要处理的 .txt 文本文件。
程序会自动尝试多种编码（UTF-8、GBK 等）读取，并显示总 Token 数。
选择分块模式
模式 A（推荐用于通用文本）
适合无明确章节结构的长文（如论文、报告、网页内容）。
模式 B（推荐用于小说/书籍）
适合有清晰章节划分的文本（如小说、教材、技术文档）。
设置参数
模式 A 参数：
目标 Token 大小：每块的目标长度（默认 2500）
重叠率：相邻块重叠比例（默认 0.05，即 5%）
最小区块比例：防止过小块的阈值（默认 0.2，即至少 20% 目标大小）
模式 B 参数：
最大 Token 上限：每个输出块的最大 Token 数（默认 5000）
开始分块
点击“开始分块”按钮，程序将在项目目录下创建 OUT/时间_文件名/ 文件夹。
输出包含：
所有分块文本文件（.txt）
（仅模式 A）metadata/ 文件夹中的 JSON 元数据（记录位置、Token 数等）
完成提示
成功后弹窗显示分块数量及保存路径。
如遇错误，将显示具体原因（如编码问题、参数无效等）。
注意事项
输入文件应为纯文本（.txt），不支持 Word/PDF 等格式。
Token 计算基于 OpenAI 的 cl100k_base 编码（与 GPT-3.5/4 一致）。
模式 B 依赖正则匹配识别章节标题，对非标准格式可能失效。
输出文件统一使用 UTF-8 编码。
✅ 适用于本地部署、批量预处理、RAG 数据准备等场景。

## 模块2：文件批处理模块使用说明
功能简介
本工具是一款功能全面的大模型文本处理平台，支持 单文件/批量文件夹处理，具备以下核心能力：
✅ API 配置管理：适配 OpenAI 兼容接口（如 Ollama、vLLM、本地部署模型等）
📁 批量处理 + 断点续传：自动跳过已处理文件，支持失败重试（最多 3 次）
💬 提示词 & 系统预设管理：可保存/加载提示模板和系统角色设定
🔧 正则后处理：自定义规则清洗输出结果（如清理多余空行、格式标准化）
📊 实时进程监控：可视化进度条、文件状态（✅成功 / ❌失败 / 🔄处理中）
📝 完整日志记录：每个任务生成独立日志，便于调试与追溯
使用流程
第一步：配置 API（首次运行必做）
启动程序后自动打开 “大模型API配置”窗口
填写：
API 地址（默认 http://localhost:11434/api/generate，适用于 Ollama）
API 密钥（如使用需填写，否则留空）
超时时间（建议 ≥180 秒）
批量间隔（防止请求过快，默认 3 秒）
点击 “测试连接” → 自动获取可用模型列表
从下拉框选择目标模型 → “保存配置”
⚠️ 注意：程序会自动将 /api/generate 转换为兼容 OpenAI 的 /v1/chat/completions 接口。
第二步：主界面操作
1. 选择处理模式
单文件模式：处理单个 .txt 文件
批量文件夹模式：处理整个文件夹内所有 .txt 文件（支持断点续传）
2. 设置处理逻辑
表格
区域	说明
输入提示词	主要指令（如“润色以下文本”），支持多行编辑
系统预设（可选）	设定 AI 角色（如“你是一位专业编辑”）
正则后处理规则	每行格式：`pattern
💡 所有区域均支持 保存/加载（.prompt / .preset / .regex 文件）
3. 开始处理
点击 “开始处理”
程序将在 OUT/ 目录下创建带时间戳的任务文件夹
输出包含：
处理结果文件（*_out.txt 或 *_processed.txt）
详细日志（*_log.txt）
失败文件会生成 _error.txt 占位符
高级特性
🔁 断点续传
批量模式下，若中途停止，再次运行会自动跳过已成功处理的文件
仅处理剩余或失败的文件，避免重复计算
🔄 自动重试机制
单个文件失败时，自动重试最多 3 次，每次间隔 10 秒
仍失败则生成错误报告，不影响其他文件
📂 输出结构示例
OUT/
└── 20260110_143022_小说批任务/
    ├── chapter01_processed.txt
    ├── chapter02_error.txt
    └── batch_log.txt          # 完整处理日志
⚙️ 快捷操作
保存当前设置：一键导出 .profile 文件（含提示词+预设+正则）
重新配置API：随时返回修改模型或密钥
自动打开结果文件夹：处理完成后弹窗并尝试打开输出目录（Windows）
注意事项
输入文件必须为 UTF-8/GBK 等常见编码的纯文本（.txt）
正则规则中的 \n、\t 需写为字面量（程序会自动转义）
若使用 Ollama，请确保模型已通过 ollama pull 下载
网络不稳定时，建议增大 超时时间 和 批量间隔
✅ 适用于：内容润色、格式转换、数据清洗、批量摘要、本地 LLM 自动化处理等场景。

## 模块3：一键合并拆分文本模块操作说明
功能  
自动将符合命名规则的多个 .txt 拆分文件按原始来源合并为一个完整文档。
文件命名要求  
文件名必须严格遵循格式：  
AAA_chunk_NBBB.txt  
- AAA：主文件名（任意非空字符串）  
- N：段落序号（纯数字，如 1、2、3…）  
- BBB：可选后缀（可为空，用于区分不同批次）  
示例：report_chunk_1.txt、novel_chunk_05_end.txt
使用步骤  
1. 运行程序：双击执行脚本  
2. 选择文件夹：在弹出窗口中选择包含拆分文件的文件夹  
3. 自动生成：  
   - 程序会按 AAA 分组，将同一组内所有 _chunk_N 文件按数字序号排序合并  
   - 输出文件命名为 AAA_zong_out.txt（如 report_zong_out.txt）  
4. 查看结果：  
   - 合并完成后自动打开结果所在文件夹  
   - 每个段落以 【段落001】 标题开头，段落间用 ---- 分隔  
注意事项  
- 仅处理 .txt 文件，其他格式自动忽略  
- 若文件读取失败，对应段落会标记 [读取失败]  
- 同一 AAA 组内的文件必须连续编号（不要求从1开始）
