# 🐱 猫仔多文助手 V2.0

> **智能文本处理工具套件** - 大模型文件批处理的完整解决方案  
> 作者：lovelycateman @ www.52pojie.cn  
> 开源理念：人人为我，我为人人

---

## 📋 目录

- [简介](#-简介)
- [功能特性](#-功能特性)
- [快速开始](#-快速开始)
- [工具详解](#-工具详解)
- [使用流程](#-使用流程)
- [参数说明](#-参数说明)
- [常见问题](#-常见问题)
- [更新日志](#-更新日志)

---

## 🎯 简介

**猫仔多文助手**是一套完整的文本处理工具集，专为大模型批量处理长文本而设计。包含两大核心工具：

1. **猫仔文本分割器** - 智能分割长文本为适合大模型处理的小块
2. **猫仔多文伴侣** - 批量调用大模型API处理文本并自动汇总

### 适用场景

✅ 小说改写、润色、缩写  
✅ 长文档翻译、总结  
✅ 文本风格转换  
✅ 批量内容处理  
✅ 任何需要大模型处理长文本的场景

### 核心优势

🚀 **自动化** - 一键完成从分割到处理再到汇总的全流程  
🎯 **智能分割** - 三种分割模式，保持语义完整性  
🔄 **容错机制** - 自动重试、一键纠错、循环纠错  
📊 **相似度检测** - 防止大模型"复读"原文  
⚡ **并发处理** - 多线程提升处理速度  
💾 **配置管理** - 保存常用配置，开箱即用  

---

## ✨ 功能特性

### 🔪 猫仔文本分割器

#### 三种智能分割模式

**模式A：Token精细分块**
- 按指定Token大小精确分割
- 保留句子边界，不破坏语义
- 支持块重叠，保持上下文连贯
- 适合：对分块大小有严格要求的场景

**模式B：按章节分块**
- 自动识别章节标题（支持中英文）
- 保持章节完整性
- 智能合并小章节
- 适合：小说、教材等有明确章节结构的文本

**模式C：章节段落混合模式**（推荐⭐）
- 先按章节分割，超限章节再细分
- 兼顾语义完整性和大小控制
- 自动编号，便于后续汇总
- 适合：大多数长文本处理场景

#### 核心功能
- ✅ 多编码支持（UTF-8、GBK、Shift-JIS等）
- ✅ Token精确计算（基于tiktoken）
- ✅ 句子边界智能识别
- ✅ 段落格式保留
- ✅ 元数据自动生成
- ✅ 结果文件夹自动打开

### 🤖 猫仔多文伴侣

#### 批量处理功能
- **文件夹批量处理** - 一次处理多个文件
- **单文档处理** - 支持处理单个文档
- **实时进度监控** - 直观查看每个文件状态
- **暂停/继续** - 灵活控制处理流程

#### 智能纠错系统
- **一键纠错** - 自动重新处理失败的文件
- **循环纠错** - 持续处理直到全部成功
- **优化文档** - 选择性重新处理特定文件

#### 相似度检测
- 自动计算输入输出相似度
- 排除标点符号干扰
- 可自定义相似度阈值（30%-100%）
- 有效防止模型"复读"原文

#### 结果汇总
自动汇总chunk文件，生成两个版本：
- **带标签版本** `_zong(title).txt` - 包含段落标签和分隔符
- **纯净版本** `_zong(clean).txt` - 仅保留内容，空行分隔

#### API管理
- 多API密钥保存与管理
- 自动测试连接并获取模型列表
- 支持OpenAI格式的各类API

#### 配置系统
- **配置确认机制** - 防止误操作
- **提示词管理** - 保存/加载自定义提示词
- **正则后处理** - 支持自定义规则清理输出
- **预设管理** - 系统级预设消息

---

## 🚀 快速开始

### 第一次使用（3步搞定）

#### 1. 环境配置
```bash
# Windows用户：双击运行
环境修复.bat
```
- ✅ 自动检测并安装Python 3.12
- ✅ 自动安装必需依赖（requests、tiktoken）
- ✅ 配置国内镜像源（无需科学上网）
- ✅ 全程自动��，无需手动操作

#### 2. 启动程序
```bash
# 双击运行任一启动脚本：
1.开始-猫仔文本分割器.bat
2.开始-猫仔多文伴侣（文件批处理）.bat

# 或直接运行Python文件：
启动程序.bat
```

#### 3. 配置API（仅多文伴侣需要）
1. 填写API地址和密钥
2. 点击"测试连接"获取模型列表
3. 点击"保存并启用模型"
4. 填写提示词
5. 点击"确认当前配置"

### 日常使用流程

```mermaid
graph LR
    A[长文本] --> B[文本分割器]
    B --> C[chunk文件]
    C --> D[多文伴侣批处理]
    D --> E[处理结果]
    E --> F[汇总输出]
    F --> G[完整文档]
```

**完整步骤：**

1. **分割文本**
   - 运行 `1.开始-猫仔文本分割器.bat`
   - 选择文件，设置参数，开始分割
   - 得到多个chunk文件

2. **批量处理**
   - 运行 `2.开始-猫仔多文伴侣（文件批处理）.bat`
   - 选择包含chunk文件的文件夹
   - 点击"确认当前配置"
   - 点击"开始"处理

3. **查看结果**
   - 点击"查看输出文件夹"
   - 检查处理结果

4. **纠错（如需要）**
   - 如有失败文件，点击"一键纠错"
   - 或使用"循环纠错"直到全部成功

5. **汇总输出**
   - 点击"汇总输出结果"
   - 自动生成两个版本的完整文档

---

## 🛠️ 工具详解

### 猫仔文本分割器

#### 界面说明

```
┌─────────────────────────────────────┐
│   猫仔文本分割器 V2.0                  │
├─────────────────────────────────────┤
│ [选择文件]  文件名.txt               │
│ 总Token数量: 50,000                  │
├─────────────────────────────────────┤
│ 分块模式：                            │
│ ○ 模式A：Token精细分块               │
│ ● 模式B：按章节分块                  │
│ ○ 模式C：章节段落混合（推荐）         │
├─────────────────────────────────────┤
│ 参数设置：                            │
│ 目标Token大小: [2500]                │
│ 重叠率: [0.05]                       │
│ 最小区块比例: [0.2]                  │
├─────────────────────────────────────┤
│          [开始分块]                   │
└─────────────────────────────────────┘
```

#### 输出结构

```
OUT/
└── 20260117_143000_文件名/
    ├── 文件名_chunk_001(第一章).txt
    ├── 文件名_chunk_002(第二章).txt
    ├── 文件名_chunk_003(第三章_part1).txt
    ├── 文件名_chunk_004(第三章_part2).txt
    └── ...
```

### 猫仔多文伴侣

#### 主界面布局

```
┌─────────────────────────────────────────────────┐
│            猫仔多文伴侣 V2.0                       │
├─────────────────────────────────────────────────┤
│ API配置                                          │
│ API地址: [http://127.0.0.1:9093/v1/...]         │
│ 密钥: [••••••••] [加载] [删除]                   │
│ 模型: [模型名称▼] [测试连接] [保存并启用模型]    │
│ 参数: 超时 重试 并发 相似度阈值...               │
├───────────────────────────────────────────────���─┤
│ 文件选择                                         │
│ ○ 文件夹模式  ○ 文档模式                        │
│ [选择输入文档/文件夹] [打开输入文件夹]           │
├─────────────────────────────────────────────────┤
│ 提示词 │ 预设 │ 正则 │        进度监控 │        │
├─────────────────────────────────────────────────┤
│ [▶开始] [⏸暂停] [确认当前配置]                  │
│ [🔧一键纠错] [🔄循环纠错] [✨优化文档]          │
│ [📁查看输出] [📋汇总输出]                       │
├─────────────────────────────────────────────────┤
│ 日志输出...                                      │
└─────────────────────────────────────────────────┘
```

#### 输出结构

```
OUT/
└── 20260117_143000_chunk文件夹/
    ├── 文件名_chunk_001_processed.txt
    ├── 文件名_chunk_002_processed.txt
    ├── 文件名_chunk_003_error.txt
    ├── ...
    ├── 文件名_zong(title).txt    # 带标签版
    └── 文件名_zong(clean).txt    # 纯净版
```

---

## ⚙️ 参数说明

### 文本分割器参数

| 参数 | 说明 | 默认值 | 建议范围 |
|------|------|--------|----------|
| 目标Token大小 | 每个块的目标token数 | 2500 | 1000-5000 |
| 重叠率 | 块之间的重叠比例 | 0.05 | 0-0.2 |
| 最小区块比例 | 最小块占目标大小的比例 | 0.2 | 0.1-0.5 |
| 最大Token上限 | 章节模式的上限 | 5000 | 3000-10000 |

### 多文伴侣参数

| 参数 | 说明 | 默认值 | 建议范围 |
|------|------|--------|----------|
| 超时(秒) | API调用超时时间 | 600 | 300-1200 |
| 并发数 | 同时处理文件数 | 2 | 1-5 |
| 重试次数 | 失败后重试次数 | 3 | 1-5 |
| 相似度阈值(%) | 防复读的相似度上限 | 40 | 30-60 |
| 最大输入值 | 单次输入token数 | 600 | 500-2000 |
| 最大输出值 | 单次输出token数 | 600 | 500-2000 |

### 提示词模板

```
核心原则：
1. 仅输出结果，不展示分析过程
2. 严禁复读原文
3. 保留所有关键情节和细节
4. 输出必须用<content></content>标签包裹

处理要求：
[在此详细描述你的需求]

输出格式：
<content>
处理后的文本...
</content>
```

---

## ❓ 常见问题

### 环境相关

**Q: 环境修复失败怎么办？**

A: 
1. 以管理员身份运行 `环境修复.bat`
2. 检查网络连接
3. 手动下载Python：https://mirrors.huaweicloud.com/python/3.12.0/python-3.12.0-amd64.exe
4. 安装时务必勾选"Add Python to PATH"

**Q: 提示"请先确认当前配置"？**

A: 这是V2.0新增的安全机制，点击"确认当前配置"按钮后才能开始处理

**Q: 缺少tiktoken模块？**

A: 运行环境修复脚本会自动安装。或手动执行：
```bash
pip install tiktoken -i https://pypi.tuna.tsinghua.edu.cn/simple
```

### 分割相关

**Q: 如何选择分割模式？**

A:
- **模式A** - 需要精确控制块大小（如API限制严格）
- **模式B** - 文本有明确章节结构且章节大小合适
- **模式C** - 大多数情况推荐，平衡语义和大小

**Q: 分割后的文件名格式？**

A: 
- 模式A/B: `文件名_chunk_001.txt`, `文件名_chunk_002.txt`
- 模式C: `文件名_chunk_001(第一章).txt`, `文件名_chunk_002(第二章_part1).txt`

**Q: 重叠率是什么？**

A: 相邻块之间共享的内容比例。设置5%可以让大模型看到上一块的结尾，保持上下文连贯。

### 处理相关

**Q: 相似��一直过高怎么办？**

A:
1. 检查提示词是否明确禁止复读
2. 增强提示词的指导性
3. 适当提高相似度阈值（但不建议超过60%）
4. 更换质量更好的模型

**Q: 如何提高处理成功率？**

A:
1. 合理设置相似度阈值（30-50%）
2. 提示词要明确且具体
3. 适当增加重试次数
4. 使用更稳定的模型

**Q: 如何提高处理速度？**

A:
1. 增加并发数（注意API限流）
2. 减少不必要的重试
3. 使用更快的模型
4. 降低单次处理的token数

### 汇总相关

**Q: 汇总功能的文件名要求？**

A: 必须符合格式：`aaa_chunk_nnn_processed.txt`
- `aaa` - 任意前缀
- `nnn` - 三位数字编号
- 必须以 `_processed.txt` 结尾

**Q: 两个汇总版本有什么区别？**

A:
- **_zong(title).txt** - 带【段落001】标签和----分隔符，便于定位
- **_zong(clean).txt** - 纯净版本，仅用空行分隔，便于阅读

**Q: 如何处理汇总后的格式问题？**

A: 使用正则后处理功能：
```
多余的换行|        # 清理多余换行
<content>|          # 删除标签
</content>|
```

### API相关

**Q: 支持哪些API？**

A: 支持OpenAI兼容格式的API：
- OpenAI官方API
- 国内各大模型API（通义千问、文心一言等）
- 本地部署（vLLM、text-generation-webui等）

**Q: API密钥安全吗？**

A: 密钥加密存储在本地`api_keys.json`文件中，不会上传到网络

**Q: 处理过程中断了怎么办？**

A: 
1. 查看日志了解中断原因
2. 已处理成功的文件不会重复处理
3. 使用"一键纠错"继续处理失败的文件

---

## 💡 使用技巧

### 提高质量

1. **精心设计提示词**
   - 明确说明处理要求
   - 强调禁止复读
   - 给出输出示例
   - 使用<content>标签包裹

2. **合理设置参数**
   - 相似度阈值：30-50%（太低误判，太高放过复读）
   - 重试次数：3-5次
   - 并发数：根据API限流调整

3. **善用纠错功能**
   - 首次处理完检查结果
   - 使用"优化文档"重新处理不满意的文件
   - 循环纠错直到全部成功

### 提高效率

1. **批量处理**
   - 一次选择整个文件夹
   - 使用文件夹模式而非单文档模式

2. **并发优化**
   - API无限流：并发数5
   - 有限流：并发数1-2
   - 本地部署：根据GPU显存调整

3. **分割策略**
   - 小说类：模式C，目标2000-3000 tokens
   - 技术文档：模式A，目标1500-2500 tokens
   - 对话记录：模式B，按会话分割

### 节省成本

1. **优化Token使用**
   - 控制max_tokens参数
   - 精简提示词长度
   - 使用更便宜的模型

2. **避免重复处理**
   - 首次处理前仔细检查配置
   - 利用相似度检测避免无效输出
   - 保存常用配置避免重复设置

---

## 📝 更新日志

### V2.0 - 2026/01/17

#### 🎉 重大更新

**新增功能：**
- ✨ 双版本汇总：`_zong(title)` 和 `_zong(clean)`
- ✨ 配置确认机制：强制确认配置后才能处理
- ✨ 环境修复工具：一键安装所有依赖
- ✨ 智能启动脚本：自动检测环境并引导

**文本分割器：**
- 🔪 新增模式C：章节段落混合模式
- 🔪 优化章节识别算法
- 🔪 改进Token计算精度
- 🔪 自动打开结果文件夹

**多文伴侣：**
- 🤖 智能文件名提取：自动从chunk文件提取前缀
- 🤖 按钮文本优化：更清晰的功能说明
- 🤖 改进相似度计算：排除标点符号干扰
- 🤖 增强日志输出：更详细的处理信息

**优化改进：**
- 🚀 使用国内镜像：Python和pip包均使用国内源
- 🚀 完善错误处理：更友好的错误提示
- 🚀 改进UI布局：增加标题和开源信息
- 🚀 详细使用文档：README和使用说明

### V1.x - 历史版本

- 基础批量处理功能
- API配置管理
- 相似度检测
- 一键纠错、循环���错
- 文本分割器基础功能

---

## 🔗 联系与支持

- **作者**：lovelycateman
- **社区**：www.52pojie.cn
- **理念**：人人为我，我为人人

### 如何贡献

欢迎提交问题反馈和功能建议！

如果觉得有用，请分享给更多人 ⭐

---

## 📜 许可证

本项目采用开源协议，遵循"人人为我，我为人人"的理念。

免费使用，禁止商用。如需商用，请联系作者。

---

## 🙏 致谢

感谢所有使用和反馈的用户！

感谢52pojie论坛提供的交流平台！

---

<p align="center">
  <strong>猫仔多文助手 V2.0</strong><br>
  让长文本处理变得简单高效<br>
  <em>Made with ❤️ by lovelycateman</em>
</p>
